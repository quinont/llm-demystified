# 01. Conversaci√≥n Simple (IA vs IA)

Hasta ahora, siempre hemos sido Humanos vs M√°quina. Pero, ¬øqu√© pasa si conectamos la salida de una IA a la entrada de otra?

Importante: a partir de ahora vamos a comenzar a cambiar un poco las palabras y ser mas "precisos". Por lo tanto tenemos:
- Agente: system_prompt, cual es el modelo que se va a ocupar, historial de conversaciones, en fin el codigo de python duro y puro.
- LLM: el cual es el cerebro, sin estado, solo procesa lo que le entra, aqui esta ollama y el modelo. 

En este experimento, creamos dos agentes ""aut√≥nomos"":

- üïµÔ∏è El Entrevistador (Agente A): Tiene la misi√≥n de descubrir 3 datos (Nombre, Profesi√≥n, Comida).
- üë∑ El Objetivo (Agente B): Tiene una personalidad definida y est√° dispuesto a charlar (o no, todo depende de nuestro prompt).

## üîÑ El Bucle de Retroalimentaci√≥n

El desaf√≠o t√©cnico aqu√≠ es la Gesti√≥n del Historial, y los diferentes perfiles que cargamos.

- Cuando el 'Agente A' habla, su mensaje se guarda en su propio historial como assistant.
- PERO, ese mismo mensaje debe insertarse en el historial del 'Agente B' como user, de esta forma hacemos "creer" al LLM que la conversacion es normal (maquina <-> humano).

Si no hacemos este cruce de roles, los agentes no sabr√°n que el otro les est√° hablando, y puede ser complicado para ellos entender la logica que existe.

Nota: me gusta seguir dandole una personalidad a todo esto, aunque todos sabemos que son modelos matematicos...

### Diagrama del Proceso

Para ir entendiendo mejor el proceso y como se van a dar las iteraciones, aqui un peque√±o esquema sobre el proceso:

```mermaid
sequenceDiagram
    participant A as üïµÔ∏è Agente A (Entrevistador)
    participant B as üë∑ Agente B (Objetivo)
    
    Note over A,B: Inicio del Bucle (5 Intercambios)
    
    A->>B: Genera Pregunta (Output A)
    Note right of A: Se guarda en Historial A como 'Assistant'<br/>Se guarda en Historial B como 'User'
    
    B->>A: Genera Respuesta (Output B)
    Note left of B: Se guarda en Historial B como 'Assistant'<br/>Se guarda en Historial A como 'User'
    
    loop Repetir 5 veces
        A->>B: Reacciona y Pregunta de nuevo...
        B->>A: Responde...
    end
    
    Note over A: üìù Generar Reporte Final
```

Nota: para no irnos mucho en la iteraccion entre los Agentes y que aparezcan "cosas raras" dejamos un maximo de 5 iteraciones entre el entrevistado y el objetivo.

## üéØ Objetivos del Script

1. Automatizaci√≥n: Ver c√≥mo dos LLMs pueden mantener una conversaci√≥n coherente sin intervenci√≥n humana.
2. Econom√≠a de Tokens: Instruimos a los modelos a ser breves para que el chat sea din√°mico.
3. Extracci√≥n de Informaci√≥n: Al final, le pedimos al Agente A que analice toda la conversaci√≥n y extraiga datos estructurados.

## Reto

Aqui es el momento en donde podriamos trabajar un poco mas en todo esto:
- Prueba diferentes tipos de prompt, cada sutil diferencia puede hacer que todo cambie.
- Prueba cambiar por otro modelo (mas peque√±o, mas grande, con thinking) el resultado puede ser increiblemente distinto.
- Prueba aumentar la iteracion a 10 o 100, o while true.... 


