# 01. ConversaciÃ³n Simple (IA vs IA)

Hasta ahora, siempre hemos sido **Humanos vs MÃ¡quina**. Pero, Â¿quÃ© pasa si conectamos la salida de una IA a la entrada de otra?

**Importante:** A partir de ahora vamos a comenzar a cambiar un poco las palabras y ser mÃ¡s "precisos". Por lo tanto tenemos:
- **Agente:** Es el sistema completo. Incluye el `system_prompt`, la gestiÃ³n del historial, el cÃ³digo de Python que orquesta todo.
- **LLM:** Es el cerebro sin estado. Solo procesa texto (entrada -> salida). AquÃ­ vive Ollama y el modelo.

En este experimento, creamos dos agentes "autÃ³nomos":

- ğŸ•µï¸ **El Entrevistador (Agente A):** Tiene la misiÃ³n de descubrir 3 datos (Nombre, ProfesiÃ³n, Comida).
- ğŸ‘· **El Objetivo (Agente B):** Tiene una personalidad definida y estÃ¡ dispuesto a charlar (o no, todo depende de nuestro prompt).

## ğŸ”„ El Bucle de RetroalimentaciÃ³n

El desafÃ­o tÃ©cnico aquÃ­ es la **GestiÃ³n del Historial** y los diferentes perfiles que cargamos.

- Cuando el **Agente A** habla, su mensaje se guarda en su propio historial como `assistant`.
- **PERO**, ese mismo mensaje debe insertarse en el historial del **Agente B** como `user`.

De esta forma hacemos "creer" al LLM que la conversaciÃ³n es normal (mÃ¡quina <-> humano). Si no hacemos este cruce de roles, los agentes no sabrÃ¡n que el otro les estÃ¡ hablando.

> **Nota:** Me gusta seguir dÃ¡ndole una personalidad a todo esto, aunque todos sabemos que son modelos matemÃ¡ticos...

### Diagrama del Proceso

Para ir entendiendo mejor el proceso y cÃ³mo se van a dar las iteraciones, aquÃ­ un pequeÃ±o esquema:

```mermaid
sequenceDiagram
    participant A as ğŸ•µï¸ Agente A (Entrevistador)
    participant B as ğŸ‘· Agente B (Objetivo)
    
    Note over A,B: Inicio del Bucle (5 Intercambios)
    
    A->>B: Genera Pregunta (Output A)
    Note right of A: Se guarda en Historial A como 'Assistant'<br/>Se guarda en Historial B como 'User'
    
    B->>A: Genera Respuesta (Output B)
    Note left of B: Se guarda en Historial B como 'Assistant'<br/>Se guarda en Historial A como 'User'
    
    loop Repetir 5 veces
        A->>B: Reacciona y Pregunta de nuevo...
        B->>A: Responde...
    end
    
    Note over A: ğŸ“ Generar Reporte Final
```

*Nota: Para no irnos mucho en la interacciÃ³n entre los Agentes y que aparezcan "cosas raras", dejamos un mÃ¡ximo de 5 iteraciones entre el entrevistado y el objetivo.*

## ğŸ¯ Objetivos del Script

1. **AutomatizaciÃ³n:** Ver cÃ³mo dos LLMs pueden mantener una conversaciÃ³n coherente sin intervenciÃ³n humana.
2. **EconomÃ­a de Tokens:** Instruimos a los modelos a ser breves para que el chat sea dinÃ¡mico.
3. **ExtracciÃ³n de InformaciÃ³n:** Al final, le pedimos al Agente A que analice toda la conversaciÃ³n y extraiga datos estructurados.

## Reto

AquÃ­ es el momento en donde podrÃ­as trabajar un poco mÃ¡s en todo esto:
- Prueba diferentes tipos de prompt, cada sutil diferencia puede hacer que todo cambie.
- Prueba cambiar por otro modelo (mÃ¡s pequeÃ±o, mÃ¡s grande, con thinking); el resultado puede ser increÃ­blemente distinto.
- Prueba aumentar la iteraciÃ³n a 10, 100, o un bucle infinito...

---

## â­ï¸ Siguiente Paso

Esto es divertido, pero son solo palabras. Â¿QuÃ© pasa si la IA tiene **necesidades**? Â¿Hambre? Â¿SueÃ±o?

ğŸ‘‰ **[CapÃ­tulo 02: Agentes con Estado](../02_agentes_con_estado)**
