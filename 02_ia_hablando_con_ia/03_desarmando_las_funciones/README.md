# 03. Desarmando las Funciones (Tool Calling con CURL)

En el script de Python anterior, todo ocurrÃ­a muy rÃ¡pido: el modelo decidÃ­a, el cÃ³digo se ejecutaba y el modelo respondÃ­a. ParecÃ­a magia.

AquÃ­ vamos a detener el tiempo y ver el paso a paso usando `curl`.

## ğŸ› ï¸ El Mito de la EjecuciÃ³n

Es vital entender esto: **El LLM NO ejecuta tu cÃ³digo Python.**

1.  El LLM analiza tu texto.
2.  Decide que necesita un dato externo.
3.  Te devuelve un JSON especial (`tool_calls`) y **se pausa**.
4.  TÃº (el Script/Agente) ejecutas la funciÃ³n en tu mÃ¡quina.
5.  TÃº le envÃ­as el resultado al LLM.
6.  El LLM continÃºa la frase.

## ğŸ“Š Diagrama de Secuencia

Observa cÃ³mo la "LÃ³gica de Negocio" (Python) es quien realmente trabaja.

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ Usuario (CURL)
    participant Agent as ğŸ¤– Script (Agente)
    participant LLM as ğŸ§  Ollama (LLM)

    User->>LLM: 1. POST /chat (Prompt + DefiniciÃ³n de Tools)
    Note right of User: "User: Â¿CÃ³mo estÃ¡ mi salud?"
    
    LLM->>User: 2. STOP: tool_calls
    Note left of LLM: JSON: {"name": "check_status"}
    
    Note over Agent: 3. El script detecta la peticiÃ³n...
    Agent->>Agent: 4. Ejecuta funciÃ³n check_status()
    Note over Agent: Resultado: {"hambre": 99, "energia": 5}
    
    User->>LLM: 5. POST /chat (Historial + Resultado Tool)
    Note right of User: Role: tool, Content: "{...}"
    
    LLM->>User: 6. Respuesta Final
    Note left of LLM: "Estoy hambriento y exhausto."
```

## ğŸ§ª Los Scripts

- `01_peticion_con_tools.sh`: Enviamos el prompt y le "enseÃ±amos" al modelo quÃ© herramientas existen (JSON Schema). VerÃ¡s que el modelo no responde texto, sino una solicitud de herramienta.
- `02_respuesta_con_resultado.sh`: Simulamos que ya ejecutamos la funciÃ³n y le devolvemos el resultado al modelo para que termine su frase.
- `03_peticion_con_accion.sh`: En este caso veremos cÃ³mo ejecutar una funciÃ³n con parÃ¡metros.
- `04_respuesta_accion_realizada.sh`: La respuesta que hay que devolver, dado que hicimos la acciÃ³n.

---

## ğŸ Fin del Viaje (Por ahora)

Â¡Felicidades! Has llegado al final de este recorrido.
Ahora sabes que:
1.  Los LLMs son "stateless".
2.  Podemos hablar con ellos vÃ­a HTTP.
3.  Existen muchos tipos de modelos.
4.  Podemos crear Agentes que usen herramientas.

Â¿Y ahora quÃ©? Â¡Experimenta! Crea tus propias herramientas, conecta bases de datos, haz que los agentes controlen tu casa inteligente. El lÃ­mite es tu imaginaciÃ³n (y la VRAM de tu GPU).

ğŸ”™ **[Anterior: Agentes con Estado](../02_agentes_con_estado)** | ğŸ  **[Volver al Inicio](../../README.md)**
